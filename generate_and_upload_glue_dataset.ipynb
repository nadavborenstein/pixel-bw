{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixel_datasets.glue_dataset_generator import GlueDatasetForPixel\n",
    "from pixel_datasets.dataset_transformations import SyntheticDatasetTransform, SimpleTorchTransform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import datasets\n",
    "import wandb\n",
    "import glob\n",
    "from pixel_datasets.utils.dataset_utils import CustomFont\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config=\"/home/knf792/PycharmProjects/pixel-2/configs/glue_config.yaml\", mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(args, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    transform = SimpleTorchTransform(args, rng)\n",
    "\n",
    "    train_dataset = GlueDatasetForPixel(\n",
    "        config=args, task=args.task_name, split=\"train\", transform=transform, rng=rng\n",
    "    )\n",
    "    test_dataset = GlueDatasetForPixel(\n",
    "        config=args,\n",
    "        task=args.task_name,\n",
    "        split=\"validation\",\n",
    "        transform=transform,\n",
    "        rng=rng,\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def convert_instance_to_dataset(instance):\n",
    "    new_instance = {}\n",
    "    image = instance[\"pixel_values\"].numpy()\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    new_instance[\"image\"] = Image.fromarray(image)\n",
    "    new_instance[\"label\"] = instance[\"label\"]\n",
    "    return new_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/projects/copenlu/data/nadav/cache/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached shuffled indices for dataset at /projects/copenlu/data/nadav/cache/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d50e90fd6eb0dceb.arrow\n",
      "Found cached dataset glue (/projects/copenlu/data/nadav/cache/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached shuffled indices for dataset at /projects/copenlu/data/nadav/cache/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-88b88f4d7a1e8d49.arrow\n"
     ]
    }
   ],
   "source": [
    "task = \"mrpc\"\n",
    "wandb.config.update({\"task_name\": task}, allow_val_change=True)\n",
    "train_dataset, test_dataset = get_datasets(wandb.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1792235f97dd482db9f9d2b43d595e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 2\n"
     ]
    }
   ],
   "source": [
    "new_test_dataset_as_dict = {\"image\": [], \"label\": []}\n",
    "for i in tqdm(range(len(test_dataset))):\n",
    "    instance = convert_instance_to_dataset(test_dataset[i])\n",
    "    new_test_dataset_as_dict[\"image\"].append(instance[\"image\"])\n",
    "    new_test_dataset_as_dict[\"label\"].append(instance[\"label\"])\n",
    "\n",
    "num_labels = len(set(new_test_dataset_as_dict[\"label\"]))\n",
    "print(f\"Number of labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad3b8f21f8e4a968a206d1af47f6fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 2\n"
     ]
    }
   ],
   "source": [
    "new_train_dataset_as_dict = {\"image\": [], \"label\": []}\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    instance = convert_instance_to_dataset(train_dataset[i])\n",
    "    new_train_dataset_as_dict[\"image\"].append(instance[\"image\"])\n",
    "    new_train_dataset_as_dict[\"label\"].append(instance[\"label\"])\n",
    "\n",
    "num_labels = len(set(new_train_dataset_as_dict[\"label\"]))\n",
    "print(f\"Number of labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "new_test_dataset = Dataset.from_dict(new_test_dataset_as_dict, features=datasets.Features({\"image\": datasets.Image(), \"label\": datasets.ClassLabel(num_classes=num_labels)}))\n",
    "new_train_dataset = Dataset.from_dict(new_train_dataset_as_dict, features=datasets.Features({\"image\": datasets.Image(), \"label\": datasets.ClassLabel(num_classes=num_labels)}))\n",
    "dataset = DatasetDict({\"train\": new_train_dataset, \"validation\": new_test_dataset})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47b212b35764b79b10b5385adef66c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667635daf3fe4fca8cf3aecee59b7437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7b52d7e01e47039d88f5cc80832d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5566bc4e52ab4e0dbd778b3f213e3d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b6ef04fbb54c7fad96036da10f87c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901432b3029345968be1902384dc73ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split validation to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758b4865dfc3447ca2ffdb56e19d4f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4830cfb014f6410fa818589b327fbd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcef7bb357714576acd3f6b1d76ef3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ff1ea8b67249789194174e4d378b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk(f\"/projects/copenlu/data/nadav/Datasets/pixel_glue_{task}/dataset\")\n",
    "dataset.push_to_hub(f\"pixel_glue_{task}\", token=\"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\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Genalog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
